//! å·¥å…·æ³¨å†Œè¡¨
//! 
//! ç®¡ç†å·¥å…·çš„æ³¨å†Œå’Œæ‰§è¡Œ

use crate::agent::types::*;
use regex::Regex;
use std::collections::HashMap;
use std::path::Path;
use walkdir::WalkDir;

/// å·¥å…·æ³¨å†Œè¡¨
pub struct ToolRegistry {
    workspace_path: String,
}

impl ToolRegistry {
    pub fn new(workspace_path: String) -> Self {
        Self { workspace_path }
    }

    /// æ‰§è¡Œå·¥å…·
    pub async fn execute(&self, tool_call: &ToolCall) -> ToolResult {
        let result = match tool_call.name.as_str() {
            "read_note" => self.read_note(&tool_call.params).await,
            "edit_note" => self.edit_note(&tool_call.params).await,
            "create_note" => self.create_note(&tool_call.params).await,
            "list_notes" => self.list_notes(&tool_call.params).await,
            "search_notes" => self.search_notes(&tool_call.params).await,
            "grep_search" => self.grep_search(&tool_call.params).await,
            "semantic_search" => self.semantic_search(&tool_call.params).await,
            "move_note" => self.move_note(&tool_call.params).await,
            "delete_note" => self.delete_note(&tool_call.params).await,
            "query_database" => self.query_database(&tool_call.params).await,
            "add_database_row" => self.add_database_row(&tool_call.params).await,
            "get_backlinks" => self.get_backlinks(&tool_call.params).await,
            "ask_user" => self.ask_user(&tool_call.params).await,
            "attempt_completion" => self.attempt_completion(&tool_call.params).await,
            _ => Err(format!("Unknown tool: {}", tool_call.name)),
        };

        match result {
            Ok(content) => ToolResult {
                tool_call_id: tool_call.id.clone(),
                success: true,
                content,
                error: None,
            },
            Err(e) => ToolResult {
                tool_call_id: tool_call.id.clone(),
                success: false,
                content: String::new(),
                error: Some(e),
            },
        }
    }

    /// è·å–å®Œæ•´è·¯å¾„
    fn get_full_path(&self, relative_path: &str) -> String {
        let base = Path::new(&self.workspace_path);
        let rel = relative_path.trim_start_matches('/').trim_start_matches('\\');
        base.join(rel).to_string_lossy().to_string()
    }

    /// è¯»å–ç¬”è®°
    async fn read_note(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;

        let full_path = self.get_full_path(path);
        
        let content = tokio::fs::read_to_string(&full_path).await
            .map_err(|e| format!("Failed to read file: {}", e))?;

        // æ·»åŠ è¡Œå·
        let numbered = content.lines()
            .enumerate()
            .map(|(i, line)| format!("{:4} | {}", i + 1, line))
            .collect::<Vec<_>>()
            .join("\n");

        Ok(numbered)
    }

    /// ç¼–è¾‘ç¬”è®°
    async fn edit_note(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;
        let old_string = params.get("old_string")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'old_string' parameter")?;
        let new_string = params.get("new_string")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'new_string' parameter")?;

        let full_path = self.get_full_path(path);
        
        let content = tokio::fs::read_to_string(&full_path).await
            .map_err(|e| format!("Failed to read file: {}", e))?;

        // æ£€æŸ¥ old_string æ˜¯å¦å­˜åœ¨
        if !content.contains(old_string) {
            return Err(format!(
                "old_string not found in file. Make sure it matches exactly including whitespace."
            ));
        }

        // æ›¿æ¢
        let new_content = content.replacen(old_string, new_string, 1);
        
        tokio::fs::write(&full_path, &new_content).await
            .map_err(|e| format!("Failed to write file: {}", e))?;

        Ok(format!("Successfully edited {}", path))
    }

    /// åˆ›å»ºç¬”è®°
    async fn create_note(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;
        let content = params.get("content")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'content' parameter")?;

        let full_path = self.get_full_path(path);
        
        // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if Path::new(&full_path).exists() {
            return Err(format!("File already exists: {}", path));
        }

        // åˆ›å»ºçˆ¶ç›®å½•
        if let Some(parent) = Path::new(&full_path).parent() {
            tokio::fs::create_dir_all(parent).await
                .map_err(|e| format!("Failed to create directory: {}", e))?;
        }

        tokio::fs::write(&full_path, content).await
            .map_err(|e| format!("Failed to write file: {}", e))?;

        Ok(format!("Successfully created {}", path))
    }

    /// åˆ—å‡ºç¬”è®°
    async fn list_notes(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .unwrap_or(".");
        
        // æ˜¯å¦é€’å½’åˆ—å‡º
        let recursive = params.get("recursive")
            .and_then(|v| v.as_bool())
            .unwrap_or(false);
        
        // æœ€å¤§æ·±åº¦é™åˆ¶
        let max_depth = if recursive {
            params.get("max_depth")
                .and_then(|v| v.as_i64())
                .unwrap_or(3) as usize
        } else {
            1
        };

        let full_path = self.get_full_path(path);
        let base_path = Path::new(&full_path);
        
        let mut entries = Vec::new();
        
        let walker = WalkDir::new(&full_path)
            .max_depth(max_depth)
            .into_iter()
            .filter_map(|e| e.ok());

        for entry in walker {
            let entry_path = entry.path();
            if entry_path == base_path {
                continue;
            }

            let name = entry.file_name().to_string_lossy().to_string();
            
            // è·³è¿‡éšè—æ–‡ä»¶
            if name.starts_with('.') {
                continue;
            }

            let is_dir = entry.file_type().is_dir();
            let prefix = if is_dir { "ğŸ“ " } else { "ğŸ“„ " };
            
            // é€’å½’æ¨¡å¼ä¸‹æ˜¾ç¤ºç›¸å¯¹è·¯å¾„
            if recursive {
                let rel_path = entry_path.strip_prefix(base_path)
                    .map(|p| p.to_string_lossy().to_string())
                    .unwrap_or_else(|_| name.clone());
                let indent = "  ".repeat(entry.depth().saturating_sub(1));
                entries.push(format!("{}{}{}", indent, prefix, rel_path));
            } else {
                entries.push(format!("{}{}", prefix, name));
            }
        }

        if !recursive {
            entries.sort();
        }
        
        if entries.is_empty() {
            Ok("(empty directory)".to_string())
        } else {
            Ok(entries.join("\n"))
        }
    }

    /// æœç´¢ç¬”è®°
    async fn search_notes(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let query = params.get("query")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'query' parameter")?;
        let limit = params.get("limit")
            .and_then(|v| v.as_i64())
            .unwrap_or(10) as usize;

        let query_lower = query.to_lowercase();
        let mut results = Vec::new();

        let walker = WalkDir::new(&self.workspace_path)
            .into_iter()
            .filter_map(|e| e.ok());

        for entry in walker {
            if results.len() >= limit {
                break;
            }

            let path = entry.path();
            
            // åªæœç´¢ .md æ–‡ä»¶
            if !path.extension().map(|e| e == "md").unwrap_or(false) {
                continue;
            }

            // è·³è¿‡éšè—æ–‡ä»¶
            if path.to_string_lossy().contains("/.") || path.to_string_lossy().contains("\\.") {
                continue;
            }

            if let Ok(content) = std::fs::read_to_string(path) {
                if content.to_lowercase().contains(&query_lower) {
                    let relative = path.strip_prefix(&self.workspace_path)
                        .map(|p| p.to_string_lossy().to_string())
                        .unwrap_or_else(|_| path.to_string_lossy().to_string());
                    
                    // æ‰¾åˆ°åŒ¹é…çš„è¡Œ
                    let mut matches = Vec::new();
                    for (i, line) in content.lines().enumerate() {
                        if line.to_lowercase().contains(&query_lower) {
                            matches.push(format!("  Line {}: {}", i + 1, line.trim()));
                            if matches.len() >= 3 {
                                break;
                            }
                        }
                    }
                    
                    results.push(format!("ğŸ“„ {}\n{}", relative, matches.join("\n")));
                }
            }
        }

        if results.is_empty() {
            Ok(format!("No notes found containing '{}'", query))
        } else {
            Ok(results.join("\n\n"))
        }
    }

    /// ç§»åŠ¨ç¬”è®°
    async fn move_note(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let from_path = params.get("from_path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'from_path' parameter")?;
        let to_path = params.get("to_path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'to_path' parameter")?;

        let full_from = self.get_full_path(from_path);
        let full_to = self.get_full_path(to_path);

        // åˆ›å»ºç›®æ ‡ç›®å½•
        if let Some(parent) = Path::new(&full_to).parent() {
            tokio::fs::create_dir_all(parent).await
                .map_err(|e| format!("Failed to create directory: {}", e))?;
        }

        tokio::fs::rename(&full_from, &full_to).await
            .map_err(|e| format!("Failed to move file: {}", e))?;

        Ok(format!("Successfully moved {} to {}", from_path, to_path))
    }

    /// åˆ é™¤ç¬”è®°
    async fn delete_note(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;

        let full_path = self.get_full_path(path);

        // ç§»åŠ¨åˆ°å›æ”¶ç«™
        trash::delete(&full_path)
            .map_err(|e| format!("Failed to delete file: {}", e))?;

        Ok(format!("Successfully deleted {} (moved to trash)", path))
    }

    /// è¯¢é—®ç”¨æˆ·
    async fn ask_user(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let question = params.get("question")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'question' parameter")?;

        // è¿™ä¸ªå·¥å…·ä¼šè§¦å‘å‰ç«¯æ˜¾ç¤ºé—®é¢˜ï¼Œç­‰å¾…ç”¨æˆ·å›å¤
        // å®é™…çš„å›å¤ä¼šé€šè¿‡ continueWithAnswer ä¼ å…¥
        Ok(format!("[WAITING_FOR_USER] {}", question))
    }

    /// å®Œæˆä»»åŠ¡
    async fn attempt_completion(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let result = params.get("result")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'result' parameter")?;

        Ok(format!("[TASK_COMPLETED] {}", result))
    }

    /// Grep æœç´¢ï¼ˆæ­£åˆ™è¡¨è¾¾å¼æœç´¢ï¼‰
    async fn grep_search(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let pattern = params.get("pattern")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'pattern' parameter")?;
        let search_path = params.get("path")
            .and_then(|v| v.as_str())
            .unwrap_or(".");
        let case_sensitive = params.get("case_sensitive")
            .and_then(|v| v.as_bool())
            .unwrap_or(false);
        let limit = params.get("limit")
            .and_then(|v| v.as_i64())
            .unwrap_or(20) as usize;

        // æ„å»ºæ­£åˆ™è¡¨è¾¾å¼
        let regex = if case_sensitive {
            Regex::new(pattern)
        } else {
            Regex::new(&format!("(?i){}", pattern))
        }.map_err(|e| format!("Invalid regex pattern: {}", e))?;

        let full_path = self.get_full_path(search_path);
        let mut results = Vec::new();

        let walker = WalkDir::new(&full_path)
            .into_iter()
            .filter_map(|e| e.ok());

        for entry in walker {
            if results.len() >= limit {
                break;
            }

            let path = entry.path();
            
            // åªæœç´¢ .md æ–‡ä»¶
            if !path.extension().map(|e| e == "md").unwrap_or(false) {
                continue;
            }

            // è·³è¿‡éšè—æ–‡ä»¶
            let path_str = path.to_string_lossy();
            if path_str.contains("/.") || path_str.contains("\\.") {
                continue;
            }

            if let Ok(content) = std::fs::read_to_string(path) {
                let mut file_matches = Vec::new();
                
                for (i, line) in content.lines().enumerate() {
                    if regex.is_match(line) {
                        file_matches.push(format!("  {}:{} {}", i + 1, ":", line.trim()));
                        if file_matches.len() >= 5 {
                            break;
                        }
                    }
                }

                if !file_matches.is_empty() {
                    let relative = path.strip_prefix(&self.workspace_path)
                        .map(|p| p.to_string_lossy().to_string())
                        .unwrap_or_else(|_| path.to_string_lossy().to_string());
                    
                    results.push(format!("ğŸ“„ {}\n{}", relative, file_matches.join("\n")));
                }
            }
        }

        if results.is_empty() {
            Ok(format!("No matches found for pattern '{}'", pattern))
        } else {
            Ok(format!("Found {} files matching '{}':\n\n{}", results.len(), pattern, results.join("\n\n")))
        }
    }

    /// è¯­ä¹‰æœç´¢ï¼ˆå‘é‡æœç´¢ï¼‰
    async fn semantic_search(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let query = params.get("query")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'query' parameter")?;
        let limit = params.get("limit")
            .and_then(|v| v.as_i64())
            .unwrap_or(5) as usize;

        // TODO: è°ƒç”¨ vector_db è¿›è¡Œè¯­ä¹‰æœç´¢
        // ç›®å‰å…ˆè¿”å›æç¤ºä¿¡æ¯ï¼Œåç»­é›†æˆ RAG ç³»ç»Ÿ
        Ok(format!(
            "[SEMANTIC_SEARCH] Query: '{}', Limit: {}\n\
            Note: Semantic search requires RAG indexing. Please use search_notes or grep_search for now.",
            query, limit
        ))
    }

    /// æŸ¥è¯¢æ•°æ®åº“
    async fn query_database(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let database_id = params.get("database_id")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'database_id' parameter")?;
        let filter = params.get("filter")
            .and_then(|v| v.as_object());
        let limit = params.get("limit")
            .and_then(|v| v.as_i64())
            .unwrap_or(50) as usize;

        // è¯»å–æ•°æ®åº“å®šä¹‰æ–‡ä»¶
        let db_file = format!("{}.db.json", database_id);
        let db_path = self.get_full_path(&db_file);
        
        let db_content = tokio::fs::read_to_string(&db_path).await
            .map_err(|e| format!("Failed to read database '{}': {}", database_id, e))?;
        
        let db: serde_json::Value = serde_json::from_str(&db_content)
            .map_err(|e| format!("Failed to parse database: {}", e))?;

        // è·å–åˆ—å®šä¹‰
        let columns = db.get("columns")
            .and_then(|v| v.as_array())
            .ok_or("Invalid database format: missing columns")?;

        let column_names: Vec<String> = columns.iter()
            .filter_map(|c| c.get("name").and_then(|n| n.as_str()).map(|s| s.to_string()))
            .collect();

        // æ‰«æç¬”è®°åº“æŸ¥æ‰¾å±äºæ­¤æ•°æ®åº“çš„ç¬”è®°
        let mut rows = Vec::new();
        let walker = WalkDir::new(&self.workspace_path)
            .into_iter()
            .filter_map(|e| e.ok());

        for entry in walker {
            if rows.len() >= limit {
                break;
            }

            let path = entry.path();
            if !path.extension().map(|e| e == "md").unwrap_or(false) {
                continue;
            }

            if let Ok(content) = std::fs::read_to_string(path) {
                // è§£æ frontmatter
                if let Some(fm) = Self::parse_frontmatter(&content) {
                    // æ£€æŸ¥æ˜¯å¦å±äºæ­¤æ•°æ®åº“
                    if fm.get("db").and_then(|v| v.as_str()) == Some(database_id) {
                        // åº”ç”¨è¿‡æ»¤å™¨
                        let mut matches = true;
                        if let Some(filter_obj) = filter {
                            for (key, value) in filter_obj {
                                if let Some(fm_value) = fm.get(key) {
                                    if fm_value != value {
                                        matches = false;
                                        break;
                                    }
                                } else {
                                    matches = false;
                                    break;
                                }
                            }
                        }

                        if matches {
                            let title = fm.get("title")
                                .and_then(|v| v.as_str())
                                .unwrap_or("Untitled");
                            
                            let mut row_data = vec![title.to_string()];
                            for col in &column_names {
                                let value = fm.get(col)
                                    .map(|v| match v {
                                        serde_json::Value::String(s) => s.clone(),
                                        _ => v.to_string(),
                                    })
                                    .unwrap_or_else(|| "-".to_string());
                                row_data.push(value);
                            }
                            rows.push(row_data);
                        }
                    }
                }
            }
        }

        // æ ¼å¼åŒ–è¾“å‡º
        if rows.is_empty() {
            Ok(format!("Database '{}' has no matching rows.", database_id))
        } else {
            let header = format!("| Title | {} |", column_names.join(" | "));
            let separator = format!("|{}|", vec!["---"; column_names.len() + 1].join("|"));
            let body: Vec<String> = rows.iter()
                .map(|row| format!("| {} |", row.join(" | ")))
                .collect();
            
            Ok(format!("{}\n{}\n{}", header, separator, body.join("\n")))
        }
    }

    /// æ·»åŠ æ•°æ®åº“è¡Œ
    async fn add_database_row(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let database_id = params.get("database_id")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'database_id' parameter")?;
        let title = params.get("title")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'title' parameter")?;
        let cells = params.get("cells")
            .and_then(|v| v.as_object());

        // æ„å»º frontmatter
        let mut frontmatter = format!("---\ndb: {}\ntitle: {}\n", database_id, title);
        
        if let Some(cells_obj) = cells {
            for (key, value) in cells_obj {
                let value_str = match value {
                    serde_json::Value::String(s) => s.clone(),
                    _ => value.to_string(),
                };
                frontmatter.push_str(&format!("{}: {}\n", key, value_str));
            }
        }
        frontmatter.push_str("---\n\n");

        // åˆ›å»ºç¬”è®°æ–‡ä»¶
        let safe_title = title.replace(['/', '\\', ':', '*', '?', '"', '<', '>', '|'], "_");
        let note_path = format!("{}.md", safe_title);
        let full_path = self.get_full_path(&note_path);

        if Path::new(&full_path).exists() {
            return Err(format!("Note '{}' already exists", note_path));
        }

        let content = format!("{}# {}\n\n", frontmatter, title);
        tokio::fs::write(&full_path, &content).await
            .map_err(|e| format!("Failed to create note: {}", e))?;

        Ok(format!("Successfully added row '{}' to database '{}'", title, database_id))
    }

    /// è·å–åå‘é“¾æ¥
    async fn get_backlinks(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;

        // è·å–ç¬”è®°åï¼ˆä¸å«è·¯å¾„å’Œæ‰©å±•åï¼‰
        let note_name = Path::new(path)
            .file_stem()
            .and_then(|s| s.to_str())
            .ok_or("Invalid path")?;

        // æ„å»ºåŒ¹é…æ¨¡å¼ï¼š[[note_name]] æˆ– [[note_name|alias]]
        let pattern = format!(r"\[\[{}(\|[^\]]+)?\]\]", regex::escape(note_name));
        let regex = Regex::new(&pattern).map_err(|e| format!("Regex error: {}", e))?;

        let mut backlinks = Vec::new();

        let walker = WalkDir::new(&self.workspace_path)
            .into_iter()
            .filter_map(|e| e.ok());

        for entry in walker {
            let entry_path = entry.path();
            
            // åªæœç´¢ .md æ–‡ä»¶ï¼Œä¸”ä¸æ˜¯è‡ªå·±
            if !entry_path.extension().map(|e| e == "md").unwrap_or(false) {
                continue;
            }

            let entry_relative = entry_path.strip_prefix(&self.workspace_path)
                .map(|p| p.to_string_lossy().to_string())
                .unwrap_or_default();

            // è·³è¿‡è‡ªå·±
            if entry_relative == path {
                continue;
            }

            // è·³è¿‡éšè—æ–‡ä»¶
            if entry_relative.contains("/.") || entry_relative.contains("\\.") {
                continue;
            }

            if let Ok(content) = std::fs::read_to_string(entry_path) {
                if regex.is_match(&content) {
                    // æ‰¾åˆ°åŒ…å«é“¾æ¥çš„è¡Œ
                    let mut context_lines = Vec::new();
                    for (i, line) in content.lines().enumerate() {
                        if regex.is_match(line) {
                            context_lines.push(format!("  Line {}: {}", i + 1, line.trim()));
                            if context_lines.len() >= 2 {
                                break;
                            }
                        }
                    }
                    
                    backlinks.push(format!("ğŸ“„ {}\n{}", entry_relative, context_lines.join("\n")));
                }
            }
        }

        if backlinks.is_empty() {
            Ok(format!("No backlinks found for '{}'", note_name))
        } else {
            Ok(format!("Found {} notes linking to '{}':\n\n{}", backlinks.len(), note_name, backlinks.join("\n\n")))
        }
    }

    /// è§£æ YAML frontmatter
    fn parse_frontmatter(content: &str) -> Option<serde_json::Map<String, serde_json::Value>> {
        let content = content.trim();
        if !content.starts_with("---") {
            return None;
        }

        let rest = &content[3..];
        let end_pos = rest.find("\n---")?;
        let yaml_str = &rest[..end_pos];

        // ç®€å•è§£æ YAML
        let mut map = serde_json::Map::new();
        for line in yaml_str.lines() {
            let line = line.trim();
            if line.is_empty() || line.starts_with('#') {
                continue;
            }
            if let Some(colon_pos) = line.find(':') {
                let key = line[..colon_pos].trim().to_string();
                let value = line[colon_pos + 1..].trim().to_string();
                map.insert(key, serde_json::Value::String(value));
            }
        }

        Some(map)
    }
}
